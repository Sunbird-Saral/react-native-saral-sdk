{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adca9543",
   "metadata": {},
   "source": [
    "# Experiment records\n",
    "- Trained model name: resnet_trained_model_digit_with_printed_v1_new_finetune_13_08_22_epoch_5.h5 (Fine-tuned on base model)\n",
    "- Trained for: 22 epochs\n",
    "- Augmentations used: No\n",
    "- Accuracy achieved: approx. 60%\n",
    "- Dataset used: https://www.nist.gov/srd/nist-special-database-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3efae38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys  \n",
    "import os\n",
    "sys.path.append(os.path.realpath('../../src'))\n",
    "# from predict import pred_using_h5_digit, pred_using_tflite_model\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/venkateshiyer/react-native-saral-sdk/ml_models/handwritten_digits/models/pre-trained_model/resnet_trained_model_digit_with_printed_v1_new_finetune_13_08_22_epoch_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4e257e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_using_h5_digit(model, path, gt = None, prediction= None, wrong_results = None):\n",
    "    result = {}\n",
    "    wrong_results = []\n",
    "    gt=[]\n",
    "    prediction = []\n",
    "    wrong_count=0\n",
    "    for img1 in sorted(glob.iglob(path)):\n",
    "        img=cv2.imread(img1)\n",
    "        img=cv2.resize(img,(28,28))\n",
    "        img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.astype('float32') / 255.\n",
    "        img= np.reshape(img,(1,28,28,1))\n",
    "        res=model.predict(img)\n",
    "        pred=res[0].argmax(axis=0)\n",
    "        ground_truth = int(img1.split('/')[-2])\n",
    "        gt.append(int(ground_truth))\n",
    "        prediction.append(pred)\n",
    "        result[img1] = pred\n",
    "        if pred!= int(ground_truth):\n",
    "            wrong_count+=1\n",
    "            wrong_results[img1] = pred\n",
    "    accuracy = (len(glob.glob(path))-wrong_count)/len(glob.glob(path))\n",
    "    return result, accuracy, gt, prediction, wrong_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8a5f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d752d787",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/venkateshiyer/handwritten_digits_test/0/*\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result, accuracy, gt, prediction, wrong_results \u001b[38;5;241m=\u001b[39m \u001b[43mpred_using_h5_digit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 21\u001b[0m, in \u001b[0;36mpred_using_h5_digit\u001b[0;34m(model, path, gt, prediction, wrong_results)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mint\u001b[39m(ground_truth):\n\u001b[1;32m     20\u001b[0m         wrong_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m         \u001b[43mwrong_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m     22\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(path))\u001b[38;5;241m-\u001b[39mwrong_count)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(path))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, accuracy, gt, prediction, wrong_results\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/0/*'\n",
    "result, accuracy, gt, prediction, wrong_results = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41671b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90       510\n",
      "           1       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81       510\n",
      "   macro avg       0.20      0.16      0.18       510\n",
      "weighted avg       1.00      0.81      0.90       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31acfab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgt\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gt' is not defined"
     ]
    }
   ],
   "source": [
    "# For 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25a36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/1/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b396f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980392156862745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       510\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       0.50      0.50      0.50       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47904a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc35cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/2/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae150046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4372549019607843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.44      0.61       510\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44       510\n",
      "   macro avg       0.11      0.05      0.07       510\n",
      "weighted avg       1.00      0.44      0.61       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d298ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d12a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/3/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec538cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5549019607843138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.55      0.71       510\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55       510\n",
      "   macro avg       0.10      0.06      0.07       510\n",
      "weighted avg       1.00      0.55      0.71       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d131a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/4/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2985afad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5058823529411764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           4       1.00      0.51      0.67       510\n",
      "           7       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       510\n",
      "   macro avg       0.20      0.10      0.13       510\n",
      "weighted avg       1.00      0.51      0.67       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527287ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d6039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/5/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97b5a7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6745098039215687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      0.67      0.81       510\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67       510\n",
      "   macro avg       0.12      0.08      0.10       510\n",
      "weighted avg       1.00      0.67      0.81       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c04954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f27fdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/6/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06a71efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6392156862745098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       1.00      0.64      0.78       510\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64       510\n",
      "   macro avg       0.20      0.13      0.16       510\n",
      "weighted avg       1.00      0.64      0.78       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de963004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "781c4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/7/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a94e9fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           7       1.00      0.59      0.74       510\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59       510\n",
      "   macro avg       0.20      0.12      0.15       510\n",
      "weighted avg       1.00      0.59      0.74       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3d0459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/8/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8ac55fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3392156862745098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       1.00      0.34      0.51       510\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.34       510\n",
      "   macro avg       0.10      0.03      0.05       510\n",
      "weighted avg       1.00      0.34      0.51       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db985e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/venkateshiyer/handwritten_digits_test/9/*'\n",
    "result, accuracy, gt, prediction = pred_using_h5_digit(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75c2e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6764705882352942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       1.00      0.68      0.81       510\n",
      "\n",
      "    accuracy                           0.68       510\n",
      "   macro avg       0.17      0.11      0.13       510\n",
      "weighted avg       1.00      0.68      0.81       510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/venkateshiyer/ocrtool/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gt, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab78a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
